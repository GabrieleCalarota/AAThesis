\chapter{Datasets}
The dataset used for the ICD-9-CM is a result of a mixture of 3 main datasets: emergency room discharge records, Wikipedia medical pages and ICD-9-CM vocabulary.\\
We first collected more than 700 thousands real emergency room diagnosis of an Hospital in Italy. As this dataset is still too small to apply word embedding, we enlarged the dataset with more medical data founded in Wikipedia health-related pages, providing some useful technical terms to our dataset. In the end we decided to add the correct definition of each codified diagnosis in ICD-9-CM adding its vocabulary.\\
For the general and comparison models, as we weren't able to use news data (i.e. Google-News, the most popular) because they aren't provided in italian language, we were forced to use other pre-trained models in italian. We found 2 of them with different backgrounds: the first one is the wikipedia dump of all the pages in it, the other one is provided with TED speech corpus translated in italian.\\
Due to the completely different nature of the two general purpose datasets, we expect that they will behave to the test in different way, in order to have a better point of view when testing our models.

\section{Emergency room discharge records}

We collected 705'429 diagnosis from Forlì Emergency Room Hospital. Each line of data consist of an emergency room discharge record made by: anamnesis (ancient, upcoming, pharmacological and familiar), objective examination, clinical course.

\begin{itemize}
	\item \textbf{Anamnesis}: cognitive investigation on the physiological and pathological precedents, individual and familiar, of a patient, written by doctors and aimed to the diagnosis. 
	\item \textbf{Ancient pathological anamnesis}: the chronological description of every morbid events that occurred during the patient's life with the sole exclusion of the pathology responsible for the hospitalization, which will instead be the subject of the upcoming pathological anamnesis. 
	\item \textbf{Upcoming pathological anamnesis}: contains the story that patient tells and brought him to the hospital. It must be detailed because it allows doctors to know well the onset of the morbid event.
	\item \textbf{Pharmacological anamnesis}: a list of every prescribed or self-administered medicines (over-the-counter medications).
	\item \textbf{Familiar anamnesis}: consists of a collection of informations about the health status of parents and siblings.
	\item \textbf{Objective examination}: examination of the patient conducted by the doctor. It's called \enquote*{\textit{objective}} as it refers to the search for objective signs (other than subjective symptoms reported by the patient) indicative of a morbid state. It's the first step in the formulation of the diagnosis and the setting of a therapy.
	\item \textbf{Clinical course}: a description of how the disease behaves over time.
\end{itemize}

\section{Wikipedia}

As for the main corpus of data (12'437 documents and 13'195'758 words), the method for retrieving Wikipedia corpus data has been specifically designed to get only data in a domain-specific context, such as the medical.
The process can be divided into two main parts: retrieving all the wikipedia pages in italian regarding medical topic and the dump of such pages.

\subsection{Retrieving all Wikipedia title pages}

We used the petscan software\footnote{PetScan (previously CatScan) is an external tool that searches an article category (and its subcategories) according to specified criteria to find articles, stubs, images, and categories.\\The tool can be found at: \url{https://petscan.wmflabs.org/}} to find all the relative pages to some medical category. We choose from the official categories list of Wikipedia\footnote{\url{https://en.wikipedia.org/wiki/Special:Categories}} the following category: health, medicine, medical procedures, medical diagnosis and medical specialty.

\subsubsection{Query}
The language of the page had to be in italian and we chose 2 as the depth\footnote{Depth of the category trees to search. 0 means to not use subcategories.} parameter. [See \ref{appendix:petscanQuery}]

\subsection{Downloading Wikipedia dump}
With the list of all the Wikipedia pages about medical topic, we queried the MediaWiki API\footnote{English version: \url{https://en.wikipedia.org/w/api.php}} to get all the contents. 
The parameters used were:
\begin{itemize}
	\item action = \textit{mobileview} \\
	Action parameter tells which action to perform. \textit{Mobileview} returns data needed for mobile views which consists of lighter data, with no picture and basically only text.
	\item format = \textit{json} \\
	The output data in JSON format.
	\item page = \textit{Title-of-the-page} \\
	Title of the page to process. It is a required parameter.
	\item sections = \textit{0-} \\
	Pipe-separated list of section numbers for which to return text. "all" can be used to return for all. Ranges in format "1-4" mean get sections 1,2,3,4. Ranges without second number, e.g. "1-" means get all until the end.
	\item prop = \textit{text} \\
	Which information to get. \textit{Text} means only HTML of selected sections.
\end{itemize}
%Qua ci starebbe EXAMPLE
%\begin{esempio}{Wikipedia query - mobileview}\label{ese:mobileview}
Example of the query with the page \enquote*{\textit{Epistassi}}(Nosebleed):\\
\url{https://it.wikipedia.org/w/api.php?action=mobileview\&format=json\&page=Epistassi\&sections=0-\&prop=text}
%\end{esempio}
\\\\
The response is a \textit{json} list of the HTML text from section 0 till the end. To retrieve a single document, we then parsed the HTML with HTMLParser\footnote{An HTMLParser instance is fed with HTML data and calls handler methods when start tags, end tags, text, comments, and other markup elements are encountered. The user should subclass HTMLParser and override its methods to implement the desired behavior. For more information see official documentation at: \url{https://docs.python.org/2/library/htmlparser.html}} and stripped away all the HTML tags with a customized class MLStripper in order to get Wikipedia data in plain text format. [See \ref{appendix:MLStripper}]


\section{ICD-9-CM Dictionary}

The International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) is the U.S. health system's adaptation of international ICD-9-CM standard list of six-character alphanumeric codes to describe diagnoses. Standardizing codes improves consistency among physicians in recording patient symptoms and diagnoses for the purposes of payer claims reimbursement and clinical research.
ICD-9-CM contains a list of codes corresponding to diagnoses and procedures recorded in conjunction with hospital care. These codes may be entered onto a patient's electronic health record and used for diagnostic, billing and reporting purposes. Related information also classified and codified in the system includes symptoms, patient complaints, causes of injury, and mental disorders.

\subsection{Italian translation}
The ICD-9-CM Classification, in the Italian translation prepared and published by the ISTAT, Classification of diseases, traumas and causes of death (9 revision, 1975), has been used, in accordance with the Decree of Ministry of Health of July 26, 1993, for the codification of clinical information detected through the emergency room discharge record (i.e. in italian \textit{\enquote*{Scheda di Dimissione Ospedaliera}, SDO}). With the ministerial decree n. 380 of 20 October 2000 the codification of health information of the SDOs is carried out with the classification ICD-9-CM version 1997 and subsequently, since 1 January 2006, the update to the 2002 version of the ICD-9-CM classification has been adopted, in compliance with the ministerial decree of 20 November 2005.
The classification used, which represents the Italian translation of the version 2007 of the American ICD-9-CM classification, was prepared by the Health section of the Ministry of Work, Health and Social Policies, and has been published by the Italy's \textit{Istituto Poligrafico e Zecca dello Stato}\footnote{It is responsible for printing official State publications, including the Official Journal, the State Values, including stamps (through the Values Paper Workshop) and coin denomination. IPZS also operates in the field of security anti-counterfeiting (electronic identity card, electronic passport, electronic residence permit), in the printing of vehicle license plates and in Internet services, for example, by creating and managing institutional sites and databases.}. It has been used uniformly throughout the italian national territory starting from the 1st of January 2009 for the codification of the diagnosis, main and secondary, and the main and secondary procedures contained in the SDOs.

\subsection{The classification}
The ICD-9-CM system contains two classifications, one for diseases and one for procedures, each of which is constituted by an alphabetical index and a systematic list; the following four parts are configured as follow:
\begin{itemize}
	\item alphabetical index of diseases and traumas
	\item systematic list of diseases and traumas
	\item alphabetical index of surgical interventions and diagnostic and therapeutic procedures
	\item systematic list of surgical interventions and diagnostic and therapeutic procedures
\end{itemize}
In addition there are two additional classifications:
\begin{itemize}
	\item factors influencing the state of health and the use of the facilities health (V codes)
	\item external causes of traumas and poisoning (codes E)
\end{itemize}
The alphabetical index and the systematic list of the two classifications are designed to complement each other: single clinical, pathological or procedural terms are searched in alphabetical indexes and the correctness of the codes assigned are then verified with all the accessory indications given in the relative systematic lists.

\subsection{Codes}

The dictionary is made by 16'212 codes and official diagnosis definition. In the example above %[\ref{ese:code}]
we can see the relation between code and the associated diagnosis.
\\\\
%\begin{esempio}{ICD-9-CM Code - Diagnosis}\label{ese:code}
\indent \textbf{71873} - \textit{Developmental dislocation of joint forearm}
%\end{esempio}
\subsection{Download}
The ICD-9-CM Dictionary translated in italian by the Ministry of Health is available at this link: \url{http://www.salute.gov.it/imgs/C\_17\_pubblicazioni\_2251\_ulterioriallegati\_ulterioreallegato\_6\_alleg.xls}

\section{General purpose}

In order to compare the domain-specific word embedding, we used two general purpose pre-trained model: a general Wikipedia italian dump and a model trained with TED corpus.

\subsection{Wikipedia corpus}
As Wikipedia is one of the first choice when searching for a large corpus of general data, we gathered word vectors trained with skipgram's word2vec by the
Human Language Technologies(HLT)\footnote{Istituto di Scienza e Tecnologie dell'Informazione "A. Faedo", Consiglio Nazionale delle Ricerche - Pisa, Italy.\\Site link:  \url{http://hlt.isti.cnr.it/}}.

\subsubsection{Download}
The latest italian Wikipedia dump can be found at this link:
\begin{itemize}
	\item \url{https://dumps.wikimedia.org/itwiki/latest/itwiki-latest-pages-articles.xml.bz2}
\end{itemize}
Whereas the word vectors trained with skipgram's word2vec are available at this link (In appendix \ref{appendix:loadWikiW2V} you can find an example of how to load such vectors):
\begin{itemize}
	\item \url{http://hlt.isti.cnr.it/wordembeddings/skipgram_wiki_window10_size300_neg-samples10.tar.gz}
\end{itemize}


\subsection{TED corpus}

TED stands for “Technology, Entertainment, Design” and it is the name of conferences held worldwide with the slogan “ideas worth spreading”. Video recordings of the talks at TED conferences are available on TED’s website with transcriptions and translations created by volunteers. The transcripts of more than 1,900 talks are available, and they are (partially) translated into 107 languages. Transcriptions and translations are released to the public after a review process completed by volunteers, thus minimizing possible fluctuation of the data quality.
The resources of TED Talks (transcripts, translations, videos, and audio) are accessible on the website for free, and they are allowed to be redistributed under the Creative Commons “Attribution - Non Commercial - Non Derivative” license. According to this license, the materials are available for non-commercial academic and
educational purposes as long as they are properly credited and the talks are kept unedited.
In fact, there already exist projects aiming to use TED Talks as a corpus. The Web Inventory of Transcribed and Translated Talks (WIT3), for instance, compiled a dataset of TED Talks for conducting cross-lingual machine translation tasks (\citeauthor{mauro2012wit3} \citeyear{mauro2012wit3} \cite{mauro2012wit3}). Also, the TED-LIUM project released a dataset primarily for training acoustic models (\citeauthor{rousseau2014enhancing} \citeyear{rousseau2014enhancing} \cite{rousseau2014enhancing}). It consists of 1,495 audio talks and their transcripts accompanied by 159,848 dictionary entries to show pronunciation. Another TED-as-corpus project is the NAIST-NTT TED Talk Treebank, which developed a manually annotated treebank of 10 TED Talks (\citeauthor{neubig2014naist} \citeyear{neubig2014naist} \cite{neubig2014naist}).

\subsubsection{The corpus}

The corpus was processed by Hermann and Blunsom at Oxford University for \enquote*{Multilingual Models for Compositional Distributed Semantics}, 2014 \cite{hermann2014multilingual}. They developed a massively multilingual corpus based on the TED corpus. This corpus contains English transcriptions and multilingual, sentence-aligned translations of talks from the TED conference.
While the corpus was aimed at machine translation tasks, they used the keywords associated with each talk to build a subsidiary corpus for multilingual document classification as follows.
At the end it amounts to 1'678'219 non-English sentences (the number of unique English sentences is smaller as many documents are translated into multiple languages and thus appear repeatedly in the corpus). Each document (talk) contains one or several keywords.
\subsubsection{Download}
The italian TED corpus data can be found at this link:
\begin{itemize}
	\item \url{https://wit3.fbk.eu/download.php?release=XML_releases/xml\&type=zip\&slang=ted_it-20160408.zip\&tlang=undefined}
\end{itemize}
Whereas the pre-trained vectors model can be found at this link:
\begin{itemize}
	\item \url{http://camoes.lx.it.pt/amartins/projects/data/multilingual_embeddings.it}
\end{itemize}
