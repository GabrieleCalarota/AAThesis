
    




    
\documentclass[11pt]{article}

    
    \usepackage[breakable]{tcolorbox}
    \tcbset{nobeforeafter} % prevents tcolorboxes being placing in paragraphs
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{svm\_aa\_rcv1\_d2v}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \newcommand{\prompt}[4]{
        \llap{{\color{#2}[#3]: #4}}\vspace{-1.25em}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Gabriele Calarota}\label{gabriele-calarota}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{114}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{google}\PY{n+nn}{.}\PY{n+nn}{colab} \PY{k}{import} \PY{n}{drive}
\PY{n}{drive}\PY{o}{.}\PY{n}{mount}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/content/drive}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Drive already mounted at /content/drive; to attempt to forcibly remount, call
drive.mount("/content/drive", force\_remount=True).
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{115}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{NUM\PYZus{}AUTHORS} \PY{o}{=} \PY{l+m+mi}{50}
\PY{n}{N\PYZus{}DOCS} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{N\PYZus{}DOCS\PYZus{}TEST\PYZus{}SET} \PY{o}{=} \PY{l+m+mi}{0}
\PY{n}{NORMALIZE\PYZus{}WORDS\PYZus{}IN\PYZus{}DOCS} \PY{o}{=} \PY{k+kc}{None}
\PY{n}{N\PYZus{}THRESHOLD} \PY{o}{=} \PY{k+kc}{None}
\PY{n}{USE\PYZus{}BOW}\PY{o}{=}\PY{k+kc}{False}
\PY{n}{USE\PYZus{}TFIDF}\PY{o}{=}\PY{k+kc}{True}
\PY{n}{USE\PYZus{}W2V}\PY{o}{=}\PY{k+kc}{False}
\PY{n}{PROJECT\PYZus{}NAME} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RCV1}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{DATASET\PYZus{}FILENAME} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Reuteurs/RCV1/rcv1\PYZus{}ccat\PYZus{}parsed\PYZus{}renamed.csv}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{USE\PYZus{}TEXT\PYZus{}DISTORTION} \PY{o}{=} \PY{k+kc}{False}
\PY{n}{K\PYZus{}text\PYZus{}distortion} \PY{o}{=} \PY{l+m+mi}{10000}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{116}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}pip install \PYZhy{}q tpot
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{117}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{re}
\PY{k+kn}{from} \PY{n+nn}{io} \PY{k}{import} \PY{n}{StringIO}

\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
\PY{k+kn}{import} \PY{n+nn}{xgboost} \PY{k}{as} \PY{n+nn}{xgb}
\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline

\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{SVC}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{recurrent} \PY{k}{import} \PY{n}{LSTM}\PY{p}{,} \PY{n}{GRU}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Activation}\PY{p}{,} \PY{n}{Dropout}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{embeddings} \PY{k}{import} \PY{n}{Embedding}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{normalization} \PY{k}{import} \PY{n}{BatchNormalization}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{np\PYZus{}utils}\PY{p}{,} \PY{n}{to\PYZus{}categorical}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{Tokenizer}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{sequence} \PY{k}{import} \PY{n}{pad\PYZus{}sequences}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{EarlyStopping}
\PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{preprocessing}\PY{p}{,} \PY{n}{decomposition}\PY{p}{,} \PY{n}{model\PYZus{}selection}\PY{p}{,} \PY{n}{metrics}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k}{import} \PY{n}{Pipeline}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{TfidfVectorizer}\PY{p}{,} \PY{n}{CountVectorizer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelEncoder}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k}{import} \PY{n}{TruncatedSVD}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LogisticRegression}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{MultinomialNB}\PY{p}{,} \PY{n}{BernoulliNB}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k}{import} \PY{n}{KernelPCA}\PY{p}{,} \PY{n}{PCA}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{GlobalAvgPool1D}\PY{p}{,} \PY{n}{Conv1D}\PY{p}{,} \PY{n}{MaxPooling1D}\PY{p}{,} \PY{n}{Flatten}\PY{p}{,} \PY{n}{Bidirectional}\PY{p}{,} \PY{n}{SpatialDropout1D}\PY{p}{,} \PY{n}{AveragePooling1D}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{sequence}\PY{p}{,} \PY{n}{text}
\PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{EarlyStopping}
\PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{backend} \PY{k}{as} \PY{n}{K}
\PY{k+kn}{import} \PY{n+nn}{nltk}
\PY{k+kn}{from} \PY{n+nn}{nltk} \PY{k}{import} \PY{n}{word\PYZus{}tokenize}
\PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem}\PY{n+nn}{.}\PY{n+nn}{wordnet} \PY{k}{import} \PY{n}{WordNetLemmatizer}
\PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{wordnet} \PY{k}{as} \PY{n}{wn}
\PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{stopwords}
\PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem}\PY{n+nn}{.}\PY{n+nn}{snowball} \PY{k}{import} \PY{n}{SnowballStemmer}
\PY{k+kn}{import} \PY{n+nn}{tarfile}
\PY{k+kn}{import} \PY{n+nn}{zipfile}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}selection} \PY{k}{import} \PY{n}{SelectFwe}\PY{p}{,} \PY{n}{f\PYZus{}classif}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k}{import} \PY{n}{make\PYZus{}pipeline}\PY{p}{,} \PY{n}{make\PYZus{}union}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{LinearSVC}
\PY{k+kn}{from} \PY{n+nn}{tpot}\PY{n+nn}{.}\PY{n+nn}{builtins} \PY{k}{import} \PY{n}{StackingEstimator}
\PY{k+kn}{from} \PY{n+nn}{tpot}\PY{n+nn}{.}\PY{n+nn}{export\PYZus{}utils} \PY{k}{import} \PY{n}{set\PYZus{}param\PYZus{}recursive}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{FunctionTransformer}
\PY{k+kn}{from} \PY{n+nn}{copy} \PY{k}{import} \PY{n}{copy}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}\PY{p}{,} \PY{n}{precision\PYZus{}score}\PY{p}{,} \PY{n}{recall\PYZus{}score}\PY{p}{,} \PY{n}{f1\PYZus{}score}\PY{p}{,} \PY{n}{precision\PYZus{}recall\PYZus{}curve}\PY{p}{,} \PY{n}{classification\PYZus{}report}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{118}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{nltk}
\PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stopwords}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{punkt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wordnet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[nltk\_data] Downloading package stopwords to /root/nltk\_data{\ldots}
[nltk\_data]   Package stopwords is already up-to-date!
[nltk\_data] Downloading package punkt to /root/nltk\_data{\ldots}
[nltk\_data]   Package punkt is already up-to-date!
[nltk\_data] Downloading package wordnet to /root/nltk\_data{\ldots}
[nltk\_data]   Package wordnet is already up-to-date!
\end{Verbatim}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{118}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
True
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{119}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{base\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/content/drive/Shared drives/Tesi\PYZus{}AuthorshipAttribution\PYZus{}Calarota/Dataset/}\PY{l+s+s1}{\PYZsq{}}
\PY{c+c1}{\PYZsh{}base\PYZus{}dir = \PYZdq{}\PYZdq{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{120}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{dataframe}\PY{p}{)}\PY{p}{:}
  \PY{n}{num\PYZus{}text\PYZus{}total} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{dataframe}\PY{p}{)}
  \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{df\PYZus{}count} \PY{o}{=} \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}
  \PY{n}{num\PYZus{}of\PYZus{}authors} \PY{o}{=} \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{counts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}
  \PY{n}{num\PYZus{}text\PYZus{}per\PYZus{}author\PYZus{}mean}\PY{o}{=}\PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
  \PY{n}{text\PYZus{}length\PYZus{}per\PYZus{}author}\PY{o}{=}\PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{len}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean\PYZus{}len\PYZus{}text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{c+c1}{\PYZsh{} dataframe[\PYZsq{}number\PYZus{}of\PYZus{}words\PYZsq{}] = dataframe[\PYZsq{}articles\PYZsq{}].apply(lambda x: len([word.lower() for sent in nltk.sent\PYZus{}tokenize(x) for word in nltk.word\PYZus{}tokenize(sent)]))}
  \PY{c+c1}{\PYZsh{} print(f\PYZdq{}Total words: \PYZob{}dataframe[\PYZsq{}number\PYZus{}of\PYZus{}words\PYZsq{}].sum()\PYZcb{}. Mean per article: \PYZob{}dataframe[\PYZsq{}number\PYZus{}of\PYZus{}words\PYZsq{}].mean()\PYZcb{}\PYZdq{})}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Numero di testi totale: }\PY{l+s+si}{\PYZob{}num\PYZus{}text\PYZus{}total\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Numero di testi per autore in media: }\PY{l+s+si}{\PYZob{}num\PYZus{}text\PYZus{}per\PYZus{}author\PYZus{}mean\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Numero di autori: }\PY{l+s+si}{\PYZob{}num\PYZus{}of\PYZus{}authors[\PYZsq{}author\PYZsq{}]\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Lunghezza media testo per autore in media: }\PY{l+s+s2}{\PYZob{}}\PY{l+s+s2}{text\PYZus{}length\PYZus{}per\PYZus{}author[}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{mean\PYZus{}len\PYZus{}text}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{].mean()\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{121}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dataset} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{n}{DATASET\PYZus{}FILENAME}\PY{p}{)}\PY{p}{)} 
\PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{121}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
   Unnamed: 0  {\ldots}           author
0           1  {\ldots}     David Lawder
1           2  {\ldots}  Susan Zimmerman
2           3  {\ldots}  Susan Zimmerman
3           7  {\ldots}     Susan Nadeau
4           9  {\ldots}       Greg Frost

[5 rows x 3 columns]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{122}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Numero di testi totale: 35667
Numero di testi per autore in media: 23.403543307086615
Numero di autori: 1524
Lunghezza media testo per autore in media: 3056.149551256315
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{123}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{get\PYZus{}top\PYZus{}ten\PYZus{}authors}\PY{p}{(}\PY{n}{dataframe}\PY{p}{,} \PY{n}{number\PYZus{}prune}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
  \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{df\PYZus{}count} \PY{o}{=} \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}
  \PY{n}{num\PYZus{}of\PYZus{}authors} \PY{o}{=} \PY{n}{df\PYZus{}group\PYZus{}by\PYZus{}author}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{counts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{sorted\PYZus{}authors} \PY{o}{=} \PY{n}{num\PYZus{}of\PYZus{}authors}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{counts}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
  \PY{n}{id\PYZus{}of\PYZus{}author} \PY{o}{=} \PY{n}{sorted\PYZus{}authors}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{to\PYZus{}list}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n}{number\PYZus{}prune}\PY{p}{]}
  \PY{k}{return} \PY{n}{id\PYZus{}of\PYZus{}author}

\PY{n}{list\PYZus{}of\PYZus{}top\PYZus{}ten\PYZus{}authors} \PY{o}{=} \PY{n}{get\PYZus{}top\PYZus{}ten\PYZus{}authors}\PY{p}{(}\PY{n}{dataset}\PY{p}{,} \PY{n}{number\PYZus{}prune}\PY{o}{=}\PY{n}{NUM\PYZus{}AUTHORS}\PY{p}{)}
\PY{n}{dataset} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{n}{dataset}\PY{o}{.}\PY{n}{author}\PY{o}{.}\PY{n}{isin}\PY{p}{(}\PY{n}{list\PYZus{}of\PYZus{}top\PYZus{}ten\PYZus{}authors}\PY{p}{)}\PY{p}{]}
\PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Numero di testi totale: 2644
Numero di testi per autore in media: 264.4
Numero di autori: 10
Lunghezza media testo per autore in media: 3126.2182190049957
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{124}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{get\PYZus{}only\PYZus{}n\PYZus{}docs\PYZus{}for\PYZus{}authors}\PY{p}{(}\PY{n}{dataframe}\PY{p}{,} \PY{n}{n\PYZus{}docs}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{threshold\PYZus{}document\PYZus{}length}\PY{o}{=}\PY{l+m+mi}{600}\PY{p}{)}\PY{p}{:}
  \PY{k}{if} \PY{n}{threshold\PYZus{}document\PYZus{}length} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
    \PY{n}{dataframe} \PY{o}{=} \PY{n}{dataframe}\PY{p}{[}\PY{n}{dataframe}\PY{o}{.}\PY{n}{articles}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{len}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{n}{threshold\PYZus{}document\PYZus{}length}\PY{p}{]}
  \PY{k}{if} \PY{n}{n\PYZus{}docs} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
    \PY{n}{dataframe} \PY{o}{=} \PY{n}{dataframe}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{n\PYZus{}docs}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
  \PY{k}{return} \PY{n}{dataframe}
\PY{n}{dataset} \PY{o}{=} \PY{n}{get\PYZus{}only\PYZus{}n\PYZus{}docs\PYZus{}for\PYZus{}authors}\PY{p}{(}\PY{n}{dataset}\PY{p}{,} \PY{n}{n\PYZus{}docs}\PY{o}{=}\PY{n}{N\PYZus{}DOCS}\PY{o}{+}\PY{n}{N\PYZus{}DOCS\PYZus{}TEST\PYZus{}SET}\PY{p}{,} \PY{n}{threshold\PYZus{}document\PYZus{}length}\PY{o}{=}\PY{n}{N\PYZus{}THRESHOLD}\PY{p}{)}
\PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Numero di testi totale: 1000
Numero di testi per autore in media: 100.0
Numero di autori: 10
Lunghezza media testo per autore in media: 3093.821
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{125}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dataset}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{125}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
   Unnamed: 0                                           articles         author
0           1  Chrysler Corp. Tuesday announced \$380 million {\ldots}   David Lawder
1         152  Huntsman Corp. on Tuesday dropped its \$460 mil{\ldots}    Robin Sidel
2        1171  Qantas Airways Ltd has begun a regular air car{\ldots}  Jim Gilchrist
3        1172  Qantas Airways regional general manager freigh{\ldots}  Jim Gilchrist
4        1195  Acting Indian commissioner in Hong Kong, Dipak{\ldots}  Jim Gilchrist
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{126}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{126}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
<matplotlib.axes.\_subplots.AxesSubplot at 0x7f12d4f607b8>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{svm_aa_rcv1_d2v_files/svm_aa_rcv1_d2v_13_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Train and test data are similarly distributed. An article can be
attributed to an author based on the topic and content of the article or
the author writing style or mix of both. In my basic approach, I will
try to solve the problem by leveraging the frequency of words in the
article, which represents the topic of an article. For this, I will
construct a TF-IDF matrix. I am not going to rely on the default
tokenizer provided by the scikit learn; I will create one for myself.
The custom tokenizer involved three steps:

\begin{itemize}
\tightlist
\item
  Tokenize the article into sentences and sentences into words
\item
  Filter the tokens with smaller lengths (assuming smaller words doesn't
  really say anything about the topic), whether a word is stop word or
  not, and whether the word is present in the dictionary or not
\item
  Stem the words
\end{itemize}

I am also going to construct a raw counts matrix as some models like
MultinomialNB often perform better on raw counts

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{127}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{get\PYZus{}wk\PYZus{}bnc}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{2000}\PY{p}{)}\PY{p}{:}
  \PY{n}{bnc\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bnc\PYZus{}lemma\PYZus{}parsed.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
  \PY{n}{select\PYZus{}df} \PY{o}{=} \PY{n}{bnc\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{k}\PY{p}{)}
  \PY{k}{return} \PY{n+nb}{list}\PY{p}{(}\PY{n}{select\PYZus{}df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{word}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}\PY{p}{)}

\PY{k}{if} \PY{n}{USE\PYZus{}TEXT\PYZus{}DISTORTION}\PY{p}{:}
  \PY{n}{WK} \PY{o}{=} \PY{n}{get\PYZus{}wk\PYZus{}bnc}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{n}{K\PYZus{}text\PYZus{}distortion}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{WK}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{128}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{tokenize\PYZus{}and\PYZus{}stem}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Below function tokenizes and lemmatizes the texts. It also does some cleaning by removing non dictionary words}
\PY{l+s+sd}{    This can be used to replace default tokenizer provided by feature extraction api of sklearn.}
\PY{l+s+sd}{    :param text: str}
\PY{l+s+sd}{    :return: list}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{stemmer} \PY{o}{=} \PY{n}{SnowballStemmer}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{english}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{n}{stopwords}\PY{o}{.}\PY{n}{words}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{english}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{tokens} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{sent\PYZus{}tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{sent}\PY{p}{)}\PY{p}{]}
    \PY{n}{filtered\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{tokens}\PY{p}{:}
        \PY{k}{if} \PY{n}{re}\PY{o}{.}\PY{n}{search}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[a\PYZhy{}zA\PYZhy{}Z\PYZhy{}]}\PY{l+s+s1}{\PYZob{}}\PY{l+s+s1}{4,\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{token}\PY{p}{)} \PY{o+ow}{and} \PY{n}{token} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{stop\PYZus{}words} \PY{o+ow}{and} \PY{n+nb}{len}\PY{p}{(}\PY{n}{wn}\PY{o}{.}\PY{n}{synsets}\PY{p}{(}\PY{n}{token}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
            \PY{n}{token}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}
            \PY{n}{filtered\PYZus{}tokens}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}
    \PY{n}{filtered\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{n}{stemmer}\PY{o}{.}\PY{n}{stem}\PY{p}{(}\PY{n}{token}\PY{p}{)} \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{filtered\PYZus{}tokens}\PY{p}{]}
    \PY{k}{return} \PY{n}{filtered\PYZus{}tokens}
  
\PY{k}{def} \PY{n+nf}{simple\PYZus{}tokenizer}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
    \PY{n}{text} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{([\PYZca{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{]*)}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{text}\PY{p}{)}
    \PY{n}{tokens} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{sent\PYZus{}tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{sent}\PY{p}{)}\PY{p}{]}
    \PY{n}{filtered\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{tokens}\PY{p}{:}
        \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{wn}\PY{o}{.}\PY{n}{synsets}\PY{p}{(}\PY{n}{token}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
            \PY{n}{token}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}
            \PY{n}{filtered\PYZus{}tokens}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}
    \PY{k}{return} \PY{n}{filtered\PYZus{}tokens}

\PY{k}{def} \PY{n+nf}{only\PYZus{}remove\PYZus{}quoting\PYZus{}tokenizer}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
  \PY{n}{text} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{([\PYZca{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{]*)}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{text}\PY{p}{)}
  \PY{n}{tokens} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{sent\PYZus{}tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{sent}\PY{p}{)}\PY{p}{]}
  \PY{k}{return} \PY{n}{tokens}


\PY{k}{def} \PY{n+nf}{text\PYZus{}distortion\PYZus{}tokenizer\PYZus{}DV\PYZus{}MA}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
  \PY{n}{text} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{([\PYZca{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{]*)}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{text}\PY{p}{)}
  \PY{n}{tokens} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{sent\PYZus{}tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{sent}\PY{p}{)}\PY{p}{]}
  \PY{n}{filtered\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{p}{]}
  \PY{c+c1}{\PYZsh{} implementing DV\PYZus{}MA}
  \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{tokens}\PY{p}{:}
    \PY{k}{if} \PY{n}{token}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{WK}\PY{p}{:}
      \PY{c+c1}{\PYZsh{} replacing all digits in token with \PYZsh{}}
      \PY{n}{token} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{token}\PY{p}{)}
      \PY{c+c1}{\PYZsh{} replacing each letter in t with *}
      \PY{n}{token} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[a\PYZhy{}zA\PYZhy{}Z]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{token}\PY{p}{)}
      \PY{n}{filtered\PYZus{}tokens}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}

  \PY{k}{return} \PY{n}{filtered\PYZus{}tokens}

\PY{k}{def} \PY{n+nf}{text\PYZus{}distortion\PYZus{}tokenizer\PYZus{}DV\PYZus{}SA}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
  \PY{n}{text} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{([\PYZca{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{]*)}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{text}\PY{p}{)}
  \PY{n}{tokens} \PY{o}{=} \PY{p}{[}\PY{n}{word}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{sent\PYZus{}tokenize}\PY{p}{(}\PY{n}{text}\PY{p}{)} \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{sent}\PY{p}{)}\PY{p}{]}
  \PY{n}{filtered\PYZus{}tokens} \PY{o}{=} \PY{p}{[}\PY{p}{]}
  \PY{c+c1}{\PYZsh{} implementing DV\PYZus{}MA}
  \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{tokens}\PY{p}{:}
    \PY{k}{if} \PY{n}{token}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{WK}\PY{p}{:}
      \PY{c+c1}{\PYZsh{} replacing all digits in token with \PYZsh{}}
      \PY{n}{token} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZbs{}}\PY{l+s+s2}{d+}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{token}\PY{p}{)}
      \PY{c+c1}{\PYZsh{} replacing each letter in t with *}
      \PY{n}{token} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[a\PYZhy{}zA\PYZhy{}Z]+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{*}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{token}\PY{p}{)}
      \PY{n}{filtered\PYZus{}tokens}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{token}\PY{p}{)}

  \PY{k}{return} \PY{n}{filtered\PYZus{}tokens}

\PY{c+c1}{\PYZsh{} custom\PYZus{}tokenizer = tokenize\PYZus{}and\PYZus{}stem}
\PY{c+c1}{\PYZsh{} custom\PYZus{}tokenizer = text\PYZus{}distortion\PYZus{}tokenizer\PYZus{}DV\PYZus{}MA}
\PY{c+c1}{\PYZsh{} custom\PYZus{}tokenizer = text\PYZus{}distortion\PYZus{}tokenizer\PYZus{}DV\PYZus{}SA}
\PY{c+c1}{\PYZsh{} custom\PYZus{}tokenizer = simple\PYZus{}tokenizer}
\PY{c+c1}{\PYZsh{} custom\PYZus{}tokenizer = None}
\PY{n}{custom\PYZus{}tokenizer} \PY{o}{=} \PY{n}{only\PYZus{}remove\PYZus{}quoting\PYZus{}tokenizer}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{129}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tfidf\PYZus{}vec} \PY{o}{=} \PY{n}{TfidfVectorizer}\PY{p}{(}\PY{n}{max\PYZus{}df}\PY{o}{=}\PY{l+m+mf}{0.75}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,}
                            \PY{n}{min\PYZus{}df}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{,} \PY{n}{use\PYZus{}idf}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{tokenizer}\PY{o}{=}\PY{n}{custom\PYZus{}tokenizer}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\PY{n}{counter\PYZus{}vect} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{max\PYZus{}df}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{10000}\PY{p}{,}
                               \PY{n}{min\PYZus{}df}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{,} \PY{n}{tokenizer}\PY{o}{=}\PY{n}{custom\PYZus{}tokenizer}\PY{p}{,} \PY{n}{ngram\PYZus{}range}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{130}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} df\PYZus{}clean\PYZus{}test\PYZus{}set = dataset.groupby(\PYZsq{}author\PYZsq{}).head(N\PYZus{}DOCS\PYZus{}TEST\PYZus{}SET).reset\PYZus{}index(drop=True)}
\PY{c+c1}{\PYZsh{} df\PYZus{}clean\PYZus{}test\PYZus{}set.head()}
\PY{c+c1}{\PYZsh{} print\PYZus{}stats\PYZus{}dataset(df\PYZus{}clean\PYZus{}test\PYZus{}set)}
\PY{c+c1}{\PYZsh{} dataset = pd.concat([dataset,df\PYZus{}clean\PYZus{}test\PYZus{}set]).drop\PYZus{}duplicates(keep=False)}
\PY{c+c1}{\PYZsh{} print\PYZus{}stats\PYZus{}dataset(dataset)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{131}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{if} \PY{n}{NORMALIZE\PYZus{}WORDS\PYZus{}IN\PYZus{}DOCS}\PY{p}{:}
  \PY{c+c1}{\PYZsh{} dataset[\PYZsq{}articles\PYZsq{}] = dataset[\PYZsq{}articles\PYZsq{}].apply(lambda x: \PYZdq{} \PYZdq{}.join([word.lower() for sent in nltk.sent\PYZus{}tokenize(x) for word in nltk.word\PYZus{}tokenize(sent)][:NORMALIZE\PYZus{}WORDS\PYZus{}IN\PYZus{}DOCS]))}
  \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n}{NORMALIZE\PYZus{}WORDS\PYZus{}IN\PYZus{}DOCS}\PY{p}{]}\PY{p}{)}\PY{p}{)}
  \PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{132}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Even split 50 \PYZam{} 50 per author and document}
\PY{c+c1}{\PYZsh{} df\PYZus{}train, df\PYZus{}test = train\PYZus{}test\PYZus{}split(dataset, test\PYZus{}size=0.2, random\PYZus{}state=0)}
\PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{dataset}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{N\PYZus{}DOCS}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{)}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Numero di testi totale: 500
Numero di testi per autore in media: 50.0
Numero di autori: 10
Lunghezza media testo per autore in media: 3070.9739999999997
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{133}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} get difference between dataset and df\PYZus{}train for df\PYZus{}test}
\PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{dataset}\PY{p}{,}\PY{n}{df\PYZus{}train}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{drop\PYZus{}duplicates}\PY{p}{(}\PY{n}{keep}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\PY{n}{print\PYZus{}stats\PYZus{}dataset}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Numero di testi totale: 500
Numero di testi per autore in media: 50.0
Numero di autori: 10
Lunghezza media testo per autore in media: 3116.6679999999997
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{134}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{models}\PY{n+nn}{.}\PY{n+nn}{doc2vec} \PY{k}{import} \PY{n}{TaggedDocument}
\PY{k+kn}{import} \PY{n+nn}{gensim}
\PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
\PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Doc2Vec}

\PY{k}{def} \PY{n+nf}{tag\PYZus{}dataset}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
  \PY{k}{return} \PY{n}{df}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{r}\PY{p}{:} \PY{n}{TaggedDocument}\PY{p}{(}\PY{n}{words}\PY{o}{=}\PY{n}{only\PYZus{}remove\PYZus{}quoting\PYZus{}tokenizer}\PY{p}{(}\PY{n}{r}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{tags}\PY{o}{=}\PY{p}{[}\PY{n}{r}\PY{o}{.}\PY{n}{author}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\PY{n}{df\PYZus{}train\PYZus{}tagged} \PY{o}{=} \PY{n}{tag\PYZus{}dataset}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
\PY{n}{df\PYZus{}test\PYZus{}tagged} \PY{o}{=} \PY{n}{tag\PYZus{}dataset}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{135}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{multiprocessing}

\PY{n}{cores} \PY{o}{=} \PY{n}{multiprocessing}\PY{o}{.}\PY{n}{cpu\PYZus{}count}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{cores}\PY{p}{)}
\PY{n}{model\PYZus{}dmm} \PY{o}{=} \PY{n}{Doc2Vec}\PY{p}{(}\PY{n}{dm}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{dm\PYZus{}mean}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{vector\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,} \PY{n}{window}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{negative}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{min\PYZus{}count}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{workers}\PY{o}{=}\PY{n}{cores}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.065}\PY{p}{,} \PY{n}{min\PYZus{}alpha}\PY{o}{=}\PY{l+m+mf}{0.065}\PY{p}{)}
\PY{n}{model\PYZus{}dmm}\PY{o}{.}\PY{n}{build\PYZus{}vocab}\PY{p}{(}\PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{df\PYZus{}train\PYZus{}tagged}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}\PY{p}{)}

\PY{n}{model\PYZus{}dbow} \PY{o}{=} \PY{n}{Doc2Vec}\PY{p}{(}\PY{n}{dm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{vector\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{300}\PY{p}{,} \PY{n}{negative}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{hs}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{min\PYZus{}count}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{sample} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{workers}\PY{o}{=}\PY{n}{cores}\PY{p}{)}
\PY{n}{model\PYZus{}dbow}\PY{o}{.}\PY{n}{build\PYZus{}vocab}\PY{p}{(}\PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{df\PYZus{}train\PYZus{}tagged}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}\PY{p}{)}

\PY{n}{d2v\PYZus{}model} \PY{o}{=} \PY{n}{model\PYZus{}dmm}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|| 500/500 [00:00<00:00, 451583.12it/s]\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
2
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

100\%|| 500/500 [00:00<00:00, 529049.45it/s]
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{136}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{utils}

\PY{c+c1}{\PYZsh{} time}
\PY{k}{def} \PY{n+nf}{train\PYZus{}d2v\PYZus{}model}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{df}\PY{p}{)}\PY{p}{:}
  \PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{30}\PY{p}{)}\PY{p}{:}
      \PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{utils}\PY{o}{.}\PY{n}{shuffle}\PY{p}{(}\PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{total\PYZus{}examples}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
      \PY{n}{model}\PY{o}{.}\PY{n}{alpha} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{l+m+mf}{0.002}
      \PY{n}{model}\PY{o}{.}\PY{n}{min\PYZus{}alpha} \PY{o}{=} \PY{n}{model\PYZus{}dmm}\PY{o}{.}\PY{n}{alpha}
  \PY{n}{model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{d2v\PYZus{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZus{}model.vec}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{PROJECT\PYZus{}NAME}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{c+c1}{\PYZsh{} if os.path.exists(os.path.join(base\PYZus{}dir, \PYZsq{}d2v\PYZus{}\PYZob{}\PYZcb{}\PYZus{}model.vec\PYZsq{}.format(PROJECT\PYZus{}NAME))):}
\PY{c+c1}{\PYZsh{}   model = Doc2Vec.load(os.path.join(base\PYZus{}dir, \PYZsq{}d2v\PYZus{}\PYZob{}\PYZcb{}\PYZus{}model.vec\PYZsq{}.format(PROJECT\PYZus{}NAME)))}
\PY{c+c1}{\PYZsh{} else:}
\PY{n}{train\PYZus{}d2v\PYZus{}model}\PY{p}{(}\PY{n}{d2v\PYZus{}model}\PY{p}{,} \PY{n}{df\PYZus{}train\PYZus{}tagged}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|| 500/500 [00:00<00:00, 841216.21it/s]
100\%|| 500/500 [00:00<00:00, 358671.46it/s]
100\%|| 500/500 [00:00<00:00, 632243.59it/s]
100\%|| 500/500 [00:00<00:00, 560885.80it/s]
100\%|| 500/500 [00:00<00:00, 895071.28it/s]
100\%|| 500/500 [00:00<00:00, 450516.00it/s]
100\%|| 500/500 [00:00<00:00, 1117884.86it/s]
100\%|| 500/500 [00:00<00:00, 554215.64it/s]
100\%|| 500/500 [00:00<00:00, 161979.76it/s]
100\%|| 500/500 [00:00<00:00, 351281.74it/s]
100\%|| 500/500 [00:00<00:00, 206962.60it/s]
100\%|| 500/500 [00:00<00:00, 294337.12it/s]
100\%|| 500/500 [00:00<00:00, 1163145.87it/s]
100\%|| 500/500 [00:00<00:00, 155241.10it/s]
100\%|| 500/500 [00:00<00:00, 918594.83it/s]
100\%|| 500/500 [00:00<00:00, 1219983.71it/s]
100\%|| 500/500 [00:00<00:00, 647069.42it/s]
100\%|| 500/500 [00:00<00:00, 549712.19it/s]
100\%|| 500/500 [00:00<00:00, 917389.33it/s]
100\%|| 500/500 [00:00<00:00, 1184162.62it/s]
100\%|| 500/500 [00:00<00:00, 984116.38it/s]
100\%|| 500/500 [00:00<00:00, 1015078.41it/s]
100\%|| 500/500 [00:00<00:00, 887120.14it/s]
100\%|| 500/500 [00:00<00:00, 357753.67it/s]
100\%|| 500/500 [00:00<00:00, 338961.05it/s]
100\%|| 500/500 [00:00<00:00, 1248304.76it/s]
100\%|| 500/500 [00:00<00:00, 231652.71it/s]
100\%|| 500/500 [00:00<00:00, 182519.76it/s]
100\%|| 500/500 [00:00<00:00, 887120.14it/s]
100\%|| 500/500 [00:00<00:00, 1131149.95it/s]
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{137}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{vec\PYZus{}for\PYZus{}learning}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{tagged\PYZus{}docs}\PY{p}{)}\PY{p}{:}
    \PY{n}{sents} \PY{o}{=} \PY{n}{tagged\PYZus{}docs}\PY{o}{.}\PY{n}{values}
    \PY{n}{targets}\PY{p}{,} \PY{n}{regressors} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{p}{[}\PY{p}{(}\PY{n}{doc}\PY{o}{.}\PY{n}{tags}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{model}\PY{o}{.}\PY{n}{infer\PYZus{}vector}\PY{p}{(}\PY{n}{doc}\PY{o}{.}\PY{n}{words}\PY{p}{,} \PY{n}{steps}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{doc} \PY{o+ow}{in} \PY{n}{sents}\PY{p}{]}\PY{p}{)}
    \PY{k}{return} \PY{n}{targets}\PY{p}{,} \PY{n}{regressors}
\end{Verbatim}
\end{tcolorbox}

    \subsection{=\textgreater{} Extracting
features}\label{extracting-features}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{138}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{tfidf\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{c+c1}{\PYZsh{} df\PYZus{}train, df\PYZus{}test = train\PYZus{}test\PYZus{}split(dataset, test\PYZus{}size=0.5, random\PYZus{}state=0)}
  \PY{n}{tfidf\PYZus{}train} \PY{o}{=} \PY{n}{tfidf\PYZus{}vec}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n}{tfidf\PYZus{}test} \PY{o}{=} \PY{n}{tfidf\PYZus{}vec}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{k}{return} \PY{n}{tfidf\PYZus{}train}\PY{p}{,} \PY{n}{tfidf\PYZus{}test}

\PY{k}{def} \PY{n+nf}{counter\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{n}{counter\PYZus{}train} \PY{o}{=} \PY{n}{counter\PYZus{}vect}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n}{counter\PYZus{}test} \PY{o}{=} \PY{n}{counter\PYZus{}vect}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{k}{return} \PY{n}{counter\PYZus{}train}\PY{p}{,} \PY{n}{counter\PYZus{}test}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{139}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{le} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} df\PYZus{}test[\PYZsq{}target\PYZsq{}] = le.fit\PYZus{}transform(df\PYZus{}test[\PYZsq{}author\PYZsq{}])}
\PY{c+c1}{\PYZsh{}df\PYZus{}test[\PYZsq{}author\PYZsq{}] = df\PYZus{}test[\PYZsq{}author\PYZsq{}].map(lambda s: \PYZsq{}\PYZlt{}unknown\PYZgt{}\PYZsq{} if s not in le.classes\PYZus{} else s)}
\PY{c+c1}{\PYZsh{} le.classes\PYZus{} = np.append(le.classes\PYZus{}, \PYZsq{}\PYZlt{}unknown\PYZgt{}\PYZsq{})}
\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}  \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{author}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    While above models tried to use the classify the articles based on the
words and their frequencies, I will try to build a sequence model that
tries to capture the writing style of an author. However, I am dubious
about the effectiveness of these models considering the limited amount
of data.

I will change the tokenizer by removing stem as I am going to replace
words with Glove embeddings that provide relevant words vectors to all
verb forms of a word. Below are the changes that I will make:

Remove words in the quotes as they don't contribute to capture the
writing style of the author. Not stemming the words to replace the words
with corresponsing Glove vectors Not removing stop words, as some
authors whose articles aren't published online may not hesitate to use
lot of stop words

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{140}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{build\PYZus{}custom\PYZus{}w2v\PYZus{}model}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
  \PY{k+kn}{import} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{backend} \PY{k}{as} \PY{n+nn}{K}
  \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
  \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Embedding}\PY{p}{,} \PY{n}{Lambda}
  \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{np\PYZus{}utils}
  \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{sequence}
  \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{Tokenizer}
  \PY{k+kn}{import} \PY{n+nn}{gensim}
  \PY{n}{vectorize} \PY{o}{=} \PY{n}{Tokenizer}\PY{p}{(}\PY{p}{)}
  \PY{n}{vectorize}\PY{o}{.}\PY{n}{fit\PYZus{}on\PYZus{}texts}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n}{data} \PY{o}{=} \PY{n}{vectorize}\PY{o}{.}\PY{n}{texts\PYZus{}to\PYZus{}sequences}\PY{p}{(}\PY{n}{dataset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n}{total\PYZus{}vocab} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{s}\PY{p}{)} \PY{k}{for} \PY{n}{s} \PY{o+ow}{in} \PY{n}{data}\PY{p}{)}
  \PY{n}{word\PYZus{}count} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{vectorize}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}
  \PY{n}{window\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{2}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total vocab: }\PY{l+s+si}{\PYZob{}total\PYZus{}vocab\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{word count: }\PY{l+s+si}{\PYZob{}word\PYZus{}count\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

  \PY{k}{def} \PY{n+nf}{cbow\PYZus{}model}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{window\PYZus{}size}\PY{p}{,} \PY{n}{total\PYZus{}vocab}\PY{p}{)}\PY{p}{:}
      \PY{n}{total\PYZus{}length} \PY{o}{=} \PY{n}{window\PYZus{}size}\PY{o}{*}\PY{l+m+mi}{2}
      \PY{k}{for} \PY{n}{text} \PY{o+ow}{in} \PY{n}{data}\PY{p}{:}
          \PY{n}{text\PYZus{}len} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{text}\PY{p}{)}
          \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{n}{word} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{text}\PY{p}{)}\PY{p}{:}
              \PY{n}{context\PYZus{}word} \PY{o}{=} \PY{p}{[}\PY{p}{]}
              \PY{n}{target}   \PY{o}{=} \PY{p}{[}\PY{p}{]}            
              \PY{n}{begin} \PY{o}{=} \PY{n}{idx} \PY{o}{\PYZhy{}} \PY{n}{window\PYZus{}size}
              \PY{n}{end} \PY{o}{=} \PY{n}{idx} \PY{o}{+} \PY{n}{window\PYZus{}size} \PY{o}{+} \PY{l+m+mi}{1}
              \PY{n}{context\PYZus{}word}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{text}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{begin}\PY{p}{,} \PY{n}{end}\PY{p}{)} \PY{k}{if} \PY{l+m+mi}{0} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{text\PYZus{}len} \PY{o+ow}{and} \PY{n}{i} \PY{o}{!=} \PY{n}{idx}\PY{p}{]}\PY{p}{)}
              \PY{n}{target}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{word}\PY{p}{)}
              \PY{n}{contextual} \PY{o}{=} \PY{n}{sequence}\PY{o}{.}\PY{n}{pad\PYZus{}sequences}\PY{p}{(}\PY{n}{context\PYZus{}word}\PY{p}{,} \PY{n}{maxlen}\PY{o}{=}\PY{n}{total\PYZus{}length}\PY{p}{)}
              \PY{n}{final\PYZus{}target} \PY{o}{=} \PY{n}{np\PYZus{}utils}\PY{o}{.}\PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{target}\PY{p}{,} \PY{n}{total\PYZus{}vocab}\PY{p}{)}
              \PY{k}{yield}\PY{p}{(}\PY{n}{contextual}\PY{p}{,} \PY{n}{final\PYZus{}target}\PY{p}{)} 

  \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
  \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Embedding}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{n}{total\PYZus{}vocab}\PY{p}{,} \PY{n}{output\PYZus{}dim}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{input\PYZus{}length}\PY{o}{=}\PY{n}{window\PYZus{}size}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
  \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Lambda}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{K}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{output\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,}\PY{p}{)}\PY{p}{)}\PY{p}{)}
  \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{total\PYZus{}vocab}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
  \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
      \PY{n}{cost} \PY{o}{=} \PY{l+m+mi}{0}
      \PY{k}{for} \PY{n}{contextual}\PY{p}{,} \PY{n}{final\PYZus{}target} \PY{o+ow}{in} \PY{n}{cbow\PYZus{}model}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{window\PYZus{}size}\PY{p}{,} \PY{n}{total\PYZus{}vocab}\PY{p}{)}\PY{p}{:}
          \PY{n}{cost} \PY{o}{+}\PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{train\PYZus{}on\PYZus{}batch}\PY{p}{(}\PY{n}{contextual}\PY{p}{,} \PY{n}{final\PYZus{}target}\PY{p}{)}
      \PY{n+nb}{print}\PY{p}{(}\PY{n}{i}\PY{p}{,} \PY{n}{cost}\PY{p}{)}
  \PY{n}{dimensions}\PY{o}{=}\PY{l+m+mi}{100}
  \PY{n}{vect\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{dirname}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{n}{DATASET\PYZus{}FILENAME}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vectors.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{vect\PYZus{}file}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{total\PYZus{}vocab}\PY{p}{,}\PY{n}{dimensions}\PY{p}{)}\PY{p}{)}
  \PY{n}{weights} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{get\PYZus{}weights}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
  \PY{k}{for} \PY{n}{text}\PY{p}{,} \PY{n}{i} \PY{o+ow}{in} \PY{n}{vectorize}\PY{o}{.}\PY{n}{word\PYZus{}index}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
      \PY{n}{final\PYZus{}vec} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n+nb}{str}\PY{p}{,} \PY{n+nb}{list}\PY{p}{(}\PY{n}{weights}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
      \PY{n}{vect\PYZus{}file}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{text}\PY{p}{,} \PY{n}{final\PYZus{}vec}\PY{p}{)}\PY{p}{)}
  \PY{n}{vect\PYZus{}file}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}

\PY{k}{if} \PY{n}{USE\PYZus{}W2V} \PY{o+ow}{and} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{dirname}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{n}{DATASET\PYZus{}FILENAME}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vectors.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{:}
  \PY{n}{build\PYZus{}custom\PYZus{}w2v\PYZus{}model}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{141}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{scripts}\PY{n+nn}{.}\PY{n+nn}{glove2word2vec} \PY{k}{import} \PY{n}{glove2word2vec}
\PY{k+kn}{from} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{KeyedVectors}

\PY{k}{class} \PY{n+nc}{Word2VecVectorizer}\PY{p}{:}
  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{model}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Loading in word vectors...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{word\PYZus{}vectors} \PY{o}{=} \PY{n}{model}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Finished loading in word vectors}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

  \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{data}\PY{p}{)}\PY{p}{:}
    \PY{k}{pass}

  \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{data}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} determine the dimensionality of vectors}
    \PY{n}{v} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{word\PYZus{}vectors}\PY{o}{.}\PY{n}{get\PYZus{}vector}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{king}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{D} \PY{o}{=} \PY{n}{v}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

    \PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{D}\PY{p}{)}\PY{p}{)}
    \PY{n}{n} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{n}{emptycount} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{for} \PY{n}{sentence} \PY{o+ow}{in} \PY{n}{data}\PY{p}{:}
      \PY{n}{tokens} \PY{o}{=} \PY{n}{sentence}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}
      \PY{n}{vecs} \PY{o}{=} \PY{p}{[}\PY{p}{]}
      \PY{n}{m} \PY{o}{=} \PY{l+m+mi}{0}
      \PY{k}{for} \PY{n}{word} \PY{o+ow}{in} \PY{n}{tokens}\PY{p}{:}
        \PY{k}{try}\PY{p}{:}
          \PY{c+c1}{\PYZsh{} throws KeyError if word not found}
          \PY{n}{vec} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{word\PYZus{}vectors}\PY{o}{.}\PY{n}{get\PYZus{}vector}\PY{p}{(}\PY{n}{word}\PY{p}{)}
          \PY{n}{vecs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{vec}\PY{p}{)}
          \PY{n}{m} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
        \PY{k}{except} \PY{n+ne}{KeyError}\PY{p}{:}
          \PY{k}{pass}
      \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{vecs}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
        \PY{n}{vecs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{vecs}\PY{p}{)}
        \PY{n}{X}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{n}{vecs}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
      \PY{k}{else}\PY{p}{:}
        \PY{n}{emptycount} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
      \PY{n}{n} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Numer of samples with no words found: }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{ / }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{emptycount}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}\PY{p}{)}
    \PY{k}{return} \PY{n}{X}


  \PY{k}{def} \PY{n+nf}{fit\PYZus{}transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{data}\PY{p}{)}\PY{p}{:}
    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data}\PY{p}{)}
    \PY{k}{return} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{w2v\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{n}{USE\PYZus{}GLOVE} \PY{o}{=} \PY{k+kc}{False}
  \PY{k}{if} \PY{n}{USE\PYZus{}GLOVE}\PY{p}{:}
    \PY{n}{glove\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{glove.6B.50d.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{word2vec\PYZus{}output\PYZus{}file} \PY{o}{=} \PY{n}{glove\PYZus{}path}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.word2vec}\PY{l+s+s1}{\PYZsq{}}
    \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{word2vec\PYZus{}output\PYZus{}file}\PY{p}{)}\PY{p}{:}
      \PY{n}{glove2word2vec}\PY{p}{(}\PY{n}{glove\PYZus{}path}\PY{p}{,} \PY{n}{word2vec\PYZus{}output\PYZus{}file}\PY{p}{)}
  \PY{k}{else}\PY{p}{:}
    \PY{n}{word2vec\PYZus{}output\PYZus{}file} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{dirname}\PY{p}{(}
        \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{base\PYZus{}dir}\PY{p}{,} \PY{n}{DATASET\PYZus{}FILENAME}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vectors.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{model} \PY{o}{=} \PY{n}{KeyedVectors}\PY{o}{.}\PY{n}{load\PYZus{}word2vec\PYZus{}format}\PY{p}{(}\PY{n}{word2vec\PYZus{}output\PYZus{}file}\PY{p}{,} \PY{n}{binary}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

  \PY{c+c1}{\PYZsh{} Set a word vectorizer}
  \PY{n}{vectorizer} \PY{o}{=} \PY{n}{Word2VecVectorizer}\PY{p}{(}\PY{n}{model}\PY{p}{)}
  \PY{c+c1}{\PYZsh{} Get the sentence embeddings for the train dataset}
  \PY{n}{w2v\PYZus{}train} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{c+c1}{\PYZsh{} Get the sentence embeddings for the test dataset}
  \PY{n}{w2v\PYZus{}test} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{articles}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{w2v\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{w2v\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
  \PY{k}{return} \PY{n}{w2v\PYZus{}train}\PY{p}{,} \PY{n}{w2v\PYZus{}test}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{142}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{teapot\PYZus{}search}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{k+kn}{from} \PY{n+nn}{tpot} \PY{k}{import} \PY{n}{TPOTClassifier}\PY{p}{,} \PY{n}{TPOTRegressor}
  \PY{c+c1}{\PYZsh{}tpot\PYZus{}settings = dict(verbosity=2, random\PYZus{}state = 1234, scoring = \PYZsq{}accuracy\PYZsq{}, warm\PYZus{}start = True, config\PYZus{}dict=\PYZsq{}TPOT sparse\PYZsq{})}
  \PY{c+c1}{\PYZsh{}auto\PYZus{}reg = TPOTRegressor(generations=2, population\PYZus{}size=5, **tpot\PYZus{}settings)}
  \PY{c+c1}{\PYZsh{}auto\PYZus{}reg.fit(tfidf\PYZus{}train, df\PYZus{}train[\PYZsq{}target\PYZsq{}])}
  \PY{c+c1}{\PYZsh{}print(auto\PYZus{}reg.score(tfidf\PYZus{}test, df\PYZus{}test[\PYZsq{}target\PYZsq{}]))}
  \PY{c+c1}{\PYZsh{}auto\PYZus{}reg.export(\PYZsq{}tpot\PYZus{}exported\PYZus{}pipeline.py\PYZsq{})}
  \PY{c+c1}{\PYZsh{}pipeline\PYZus{}optimizer = TPOTClassifier()}
  \PY{n}{pipeline\PYZus{}optimizer} \PY{o}{=} \PY{n}{TPOTClassifier}\PY{p}{(}\PY{n}{generations}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{population\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,}
                                      \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{,} \PY{n}{verbosity}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{config\PYZus{}dict}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TPOT sparse}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
  \PY{n}{pipeline\PYZus{}optimizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{tfidf\PYZus{}train}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{pipeline\PYZus{}optimizer}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{tfidf\PYZus{}test}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
  \PY{n}{pipeline\PYZus{}optimizer}\PY{o}{.}\PY{n}{export}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tpot\PYZus{}exported\PYZus{}pipeline.py}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{143}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{use\PYZus{}features}\PY{p}{(}\PY{n}{tfidf}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{bow}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{w2v}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
  \PY{k}{if} \PY{n}{tfidf}\PY{p}{:}
    \PY{k}{return} \PY{n}{tfidf\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}
  \PY{k}{elif} \PY{n}{bow}\PY{p}{:}
    \PY{k}{return} \PY{n}{counter\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}
  \PY{k}{elif} \PY{n}{w2v}\PY{p}{:}
    \PY{k}{return} \PY{n}{w2v\PYZus{}fit\PYZus{}transform}\PY{p}{(}\PY{p}{)}
  \PY{k}{else}\PY{p}{:}
    \PY{k}{return} \PY{n}{tfidf\PYZus{}train}\PY{p}{,} \PY{n}{tfidf\PYZus{}test}

\PY{c+c1}{\PYZsh{} tfidf\PYZus{}training\PYZus{}features, tfidf\PYZus{}testing\PYZus{}features = use\PYZus{}features(tfidf=USE\PYZus{}TFIDF, bow=USE\PYZus{}BOW, w2v=USE\PYZus{}W2V)}
\PY{c+c1}{\PYZsh{} training\PYZus{}target = df\PYZus{}train[\PYZsq{}target\PYZsq{}]}
\PY{c+c1}{\PYZsh{} testing\PYZus{}target = df\PYZus{}test[\PYZsq{}target\PYZsq{}]}
\PY{n}{training\PYZus{}target}\PY{p}{,} \PY{n}{training\PYZus{}features} \PY{o}{=} \PY{n}{vec\PYZus{}for\PYZus{}learning}\PY{p}{(}\PY{n}{d2v\PYZus{}model}\PY{p}{,} \PY{n}{df\PYZus{}train\PYZus{}tagged}\PY{p}{)}
\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{testing\PYZus{}features} \PY{o}{=} \PY{n}{vec\PYZus{}for\PYZus{}learning}\PY{p}{(}\PY{n}{d2v\PYZus{}model}\PY{p}{,} \PY{n}{df\PYZus{}test\PYZus{}tagged}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{144}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{double\PYZus{}pipeline}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{c+c1}{\PYZsh{} Average CV score on the training set was: 0.9173333333333333}
  \PY{n}{exported\PYZus{}pipeline} \PY{o}{=} \PY{n}{make\PYZus{}pipeline}\PY{p}{(}
      \PY{n}{make\PYZus{}union}\PY{p}{(}
          \PY{n}{FunctionTransformer}\PY{p}{(}\PY{n}{copy}\PY{p}{)}\PY{p}{,}
          \PY{n}{SelectFwe}\PY{p}{(}\PY{n}{score\PYZus{}func}\PY{o}{=}\PY{n}{f\PYZus{}classif}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.004}\PY{p}{)}
      \PY{p}{)}\PY{p}{,}
      \PY{n}{LinearSVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{10.0}\PY{p}{,} \PY{n}{dual}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{loss}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{squared\PYZus{}hinge}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{penalty}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.000001}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
  \PY{p}{)}
  \PY{c+c1}{\PYZsh{} Fix random state for all the steps in exported pipeline}
  \PY{n}{set\PYZus{}param\PYZus{}recursive}\PY{p}{(}\PY{n}{exported\PYZus{}pipeline}\PY{o}{.}\PY{n}{steps}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{42}\PY{p}{)}
  \PY{k}{return} \PY{n}{exported\PYZus{}pipeline}

\PY{k}{def} \PY{n+nf}{single\PYZus{}pipeline}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{c+c1}{\PYZsh{} Average CV score on the training set was: 0.6912}
  \PY{n}{exported\PYZus{}pipeline} \PY{o}{=} \PY{n}{LinearSVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{20.0}\PY{p}{,} \PY{n}{dual}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{loss}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hinge}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{penalty}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{)}
  \PY{c+c1}{\PYZsh{} Fix random state in exported estimator}
  \PY{k}{if} \PY{n+nb}{hasattr}\PY{p}{(}\PY{n}{exported\PYZus{}pipeline}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
      \PY{n+nb}{setattr}\PY{p}{(}\PY{n}{exported\PYZus{}pipeline}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{42}\PY{p}{)}
  \PY{k}{return} \PY{n}{exported\PYZus{}pipeline}

\PY{k}{def} \PY{n+nf}{onevsrestclassifier}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{multiclass} \PY{k}{import} \PY{n}{OneVsRestClassifier}
  \PY{k}{return} \PY{n}{OneVsRestClassifier}\PY{p}{(}\PY{n}{LinearSVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{10.0}\PY{p}{,} \PY{n}{dual}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{loss}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{squared\PYZus{}hinge}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{penalty}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.000001}\PY{p}{,} \PY{n}{multi\PYZus{}class}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ovr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{linearsdg}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{SGDClassifier}
  \PY{k}{return} \PY{n}{SGDClassifier}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.00001}\PY{p}{,} \PY{n}{penalty}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{elasticnet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

\PY{n}{exported\PYZus{}pipeline} \PY{o}{=} \PY{n}{double\PYZus{}pipeline}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{145}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{exported\PYZus{}pipeline}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{training\PYZus{}features}\PY{p}{,} \PY{n}{training\PYZus{}target}\PY{p}{)}
\PY{n}{predicted} \PY{o}{=} \PY{n}{exported\PYZus{}pipeline}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{testing\PYZus{}features}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/usr/local/lib/python3.6/dist-packages/sklearn/svm/\_base.py:947:
ConvergenceWarning: Liblinear failed to converge, increase the number of
iterations.
  "the number of iterations.", ConvergenceWarning)
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{146}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{accuracy\PYZus{}result} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{predicted}\PY{p}{)}
\PY{n}{precision\PYZus{}result} \PY{o}{=} \PY{n}{precision\PYZus{}score}\PY{p}{(}\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{predicted}\PY{p}{,} \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{recall\PYZus{}result} \PY{o}{=} \PY{n}{recall\PYZus{}score}\PY{p}{(}\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{predicted}\PY{p}{,} \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{f1\PYZus{}result} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{predicted}\PY{p}{,} \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{macro}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}accuracy\PYZus{}result\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Precision: }\PY{l+s+si}{\PYZob{}precision\PYZus{}result\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Recall: }\PY{l+s+si}{\PYZob{}recall\PYZus{}result\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{F1\PYZus{}macro: }\PY{l+s+si}{\PYZob{}f1\PYZus{}result\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.798
Precision: 0.8142330344013349
Recall: 0.798
F1\_macro: 0.7913813067228909
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{147}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{testing\PYZus{}target}\PY{p}{,} \PY{n}{predicted}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
                  precision    recall  f1-score   support

 Alexander Smith       0.87      0.66      0.75        50
   Amelia Torres       0.92      0.92      0.92        50
    David Lawder       0.80      0.32      0.46        50
  Edna Fernandes       0.66      0.82      0.73        50
   Jim Gilchrist       0.67      0.90      0.77        50
Marcel Michelson       0.90      0.90      0.90        50
 Peter Blackburn       0.94      0.96      0.95        50
     Robin Sidel       0.96      0.98      0.97        50
 Therese Poletti       0.96      0.96      0.96        50
     Todd Nissen       0.46      0.56      0.50        50

        accuracy                           0.80       500
       macro avg       0.81      0.80      0.79       500
    weighted avg       0.81      0.80      0.79       500

\end{Verbatim}

    \subsection{REPEATED CROSS VALIDATION}\label{repeated-cross-validation}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{109}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} evaluate a logistic regression model using repeated k\PYZhy{}fold cross\PYZhy{}validation}
\PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{mean}
\PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{std}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{RepeatedKFold}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}

\PY{n}{labels\PYZus{}dataset}\PY{p}{,} \PY{n}{tfidf\PYZus{}dataset} \PY{o}{=} \PY{n}{vec\PYZus{}for\PYZus{}learning}\PY{p}{(}\PY{n}{d2v\PYZus{}model}\PY{p}{,} \PY{n}{tag\PYZus{}dataset}\PY{p}{(}\PY{n}{dataset}\PY{p}{)}\PY{p}{)}

\PY{n}{X} \PY{o}{=} \PY{n}{tfidf\PYZus{}dataset}
\PY{n}{y} \PY{o}{=} \PY{n}{labels\PYZus{}dataset}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{110}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{StratifiedKFold}\PY{p}{,} \PY{n}{KFold}\PY{p}{,} \PY{n}{StratifiedShuffleSplit}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}

\PY{n}{skf} \PY{o}{=} \PY{n}{StratifiedKFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}


\PY{c+c1}{\PYZsh{} evaluate model}
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{exported\PYZus{}pipeline}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{skf}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} report performance}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy: }\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s1}{ (}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{p}{,} \PY{n}{std}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.100 (0.000)
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{111}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{StratifiedKFold}\PY{p}{,} \PY{n}{KFold}\PY{p}{,} \PY{n}{StratifiedShuffleSplit}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}

\PY{n}{skf} \PY{o}{=} \PY{n}{StratifiedShuffleSplit}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}for train, test in skf.split(X, y):}
\PY{l+s+sd}{  print(\PYZsq{}train \PYZhy{}  \PYZob{}\PYZcb{}   |   test \PYZhy{}  \PYZob{}\PYZcb{}\PYZsq{}.format(}
\PY{l+s+sd}{      np.bincount(y[train]), np.bincount(y[test])))\PYZdq{}\PYZdq{}\PYZdq{}}


\PY{c+c1}{\PYZsh{} evaluate model}
\PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{exported\PYZus{}pipeline}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{skf}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} report performance}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy: }\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s1}{ (}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{p}{,} \PY{n}{std}\PY{p}{(}\PY{n}{scores}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.100 (0.000)
\end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{112}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Set the parameters by cross\PYZhy{}validation}
\PY{k}{def} \PY{n+nf}{cross\PYZus{}validate}\PY{p}{(}\PY{p}{)}\PY{p}{:}
  \PY{n}{tuned\PYZus{}parameters} \PY{o}{=} \PY{p}{[}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hinge}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{squared\PYZus{}hinge}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{,}
                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dual}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{True}\PY{p}{,}\PY{k+kc}{False}\PY{p}{]}\PY{p}{,}
                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tol}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{p}{,} \PY{l+m+mf}{0.0001}\PY{p}{,} \PY{l+m+mf}{0.00001}\PY{p}{,} \PY{l+m+mf}{0.000001}\PY{p}{]}\PY{p}{,}
                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}iter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{,} \PY{l+m+mi}{10000}\PY{p}{]}
                      \PY{p}{\PYZcb{}}\PY{p}{]}

  \PY{n}{clf} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}
    \PY{n}{LinearSVC}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{tuned\PYZus{}parameters}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{skf}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}
  \PY{p}{)}
  \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{training\PYZus{}features}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}

  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best parameters set found on development set:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{clf}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Grid scores on development set:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
  \PY{n}{means} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean\PYZus{}test\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
  \PY{n}{stds} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{std\PYZus{}test\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
  \PY{k}{for} \PY{n}{mean}\PY{p}{,} \PY{n}{std}\PY{p}{,} \PY{n}{params} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{means}\PY{p}{,} \PY{n}{stds}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{params}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}0.3f}\PY{l+s+s2}{ (+/\PYZhy{}}\PY{l+s+si}{\PYZpc{}0.03f}\PY{l+s+s2}{) for }\PY{l+s+si}{\PYZpc{}r}\PY{l+s+s2}{\PYZdq{}}
          \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{std} \PY{o}{*} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{params}\PY{p}{)}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}

  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Detailed classification report:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The model is trained on the full development set.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{The scores are computed on the full evaluation set.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
  \PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{testing\PYZus{}features}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
  \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{113}{\hspace{4pt}}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}pip install \PYZhy{}q python\PYZhy{}telegram\PYZhy{}bot
\PY{k+kn}{from} \PY{n+nn}{telegram} \PY{k}{import} \PY{n}{Bot}
\PY{n}{bot} \PY{o}{=} \PY{n}{Bot}\PY{p}{(}\PY{n}{token}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{627493222:AAE8dqAHnrx9JJ3AGxDwb\PYZhy{}x2eiJqoXVBM8o}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{bot}\PY{o}{.}\PY{n}{send\PYZus{}message}\PY{p}{(}\PY{n}{text}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training finito di SVM }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ on }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ authors with }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ ndocs and }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ threshold}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{PROJECT\PYZus{}NAME}\PY{p}{,} \PY{n}{NUM\PYZus{}AUTHORS}\PY{p}{,} \PY{n}{N\PYZus{}DOCS}\PY{p}{,} \PY{n}{N\PYZus{}THRESHOLD}\PY{p}{)}\PY{p}{,} \PY{n}{chat\PYZus{}id}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{141928344}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, boxrule=.5pt, size=fbox, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{113}{\hspace{3.5pt}}
\begin{Verbatim}[commandchars=\\\{\}]
<telegram.message.Message at 0x7f12d4fb2588>
\end{Verbatim}
\end{tcolorbox}
        

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
